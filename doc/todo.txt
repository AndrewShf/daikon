Daikon todo list.

Projects

  - Optimize derived variables
      - apply equality sets, constants, etc to the creation of derived
        variables
      - reduce the size of variables

  - extend the hierarchy to subclasses and interfaces.

  - Improve the splitting code and make it work for more than 2 children.

  - NIS enhancements
      - Optimize merging and checking falsified antecedents
      - support multiple levels (and binary suppressees)
      - support sample-dependent antecedents
      - Gather statistics on the power of the new invariants as antecedents.
        Remove invariants that are not justified
      - Support some subset of derived variable suppressions.  
      - Merge data from antecedents

  - Testing
      - Build better tests for NIS.  There's a number of internal
        consistency checks that would probably find additional errors
      - We could possibly test our suppressions and obvious checks against
        simplify
      - Perhaps an overall testing strategy that uses the simple 
        incremental algorithm + simplify to create known correct output
        that we could test against.  

  - Analyze Daikon over a reasonable set of programs for memory use,
    execution speed, and other interesting statistics (invariants by
    class, percent invariants obvious by class, etc).  Make this easier
    to do in the future

  - Process daikon itself (at least the main directory) over a real test
    case.  Fix problems encountered.

  - Use ourselves as test case.  This requires daikon to work on
    itself, but also will require other usability work.  In
    particular, a good way to include results as asserts.

===========================================================================

  - Testing/Validation

      - Create unit tests for more of Daikon.  Either by hand or by using
        automated tools (such as Randoop)
      - Add additional internal consistency checks that can be checked
        during system tests
      - Run Daikon on itself and add invariants (perhaps only class
        invariants) as additional assertions.
      - Add JSR308 style annotations for nullness, readonly, and possibly
        other checks.
      - Enhance track debugging to ensure that the specified ppt/class/variables
        were reasonable and existed.
      
===========================================================================

Front ends

  - Add support for loop invariants.

  - C front end

      - Everything Robert is currently doing.
        New gcc, new architectures

      - Convert Kvasir to using the new decl format.

  - C/C++ front end for Windows 

      - Similar conceptually to the existing front end for binaries on
        linux (Kvasir, which is based on the Valgrind dynamic instrumentation
        package for Linux)
      - Probably based on DynamoRio or Pin (both of which are dynamic
        instrumentation packages that support both Linux and Windows)
      - Biggest issue is determining what variables are valid (ie, refer
        to allocated/initialized memory).  Determining this is important so
        that Daikon does not attempt to use invalid (eg, uninitialized) 
        values in its inference.  Kvasir uses the memcheck package of
        Valgrind to determine this.
      - An alternative to memcheck would be to attempt to determine what
        variables were actually accessed in the call rather than considering
        all initialized variables in scope.  This could reduce the overhead
        of the front end and the number of variables that Daikon needs
        to consider.  It might miss interesting invariants (invariants over
        variables that are not accessed in a call may still be interesting)
        Its also possible that there might be heuristics short of a full
        memcheck implementation that might produce reasonable results.

  - C# front end for Windows

      Presumably this would work in a similar fashion to our existing
      Java front end (Chicory).  I spent some time, however, looking for
      dynamic instrumentation for C# and didn't find anything (but that
      doesn't mean that it doesn't exist).

      From our projects file:

        As the <a href="http://pag.csail.mit.edu/daikon/">Daikon
        invariant detector</a> (which automatically determines program
        properties, much like formal specifications) increases in
        popularity, we receive frequent requests for a front end that
        works for .NET or COM under Microsoft Windows.  A front end
        performs instrumentation, so that the program outputs trace
        information (similar to, but much more detailed than, a
        profiler) that can be processed by the invariant detector.
        Currently, we have front ends for Java and Perl, and a C/C++
        front end that works under Linux.

        This project will create a front end for either .NET or for COM.
        For instance, a MSIL (.NET) front end might take advantage of
        the Profiling API to output slightly more information than a
        profiler ordinarily does.  A COM front end could act as a
        wrapper, intercepting and recording calls between components,
        but not affecting the internal operation of the COM components
        in any way.  Other approaches are also possible (and may be
        technically superior to these suggestions).

===========================================================================

External tools

  - DynComp robustness

      DynComp/Java and DynComp/C have been successfully used on a
      number of realistic programs.  Howerver, both versions of
      DynComp requires extensive instrumentation of the application
      program in order to track all value flow in the program.  Both
      should be tested on a wider variety of programs.  Any bugs encountered
      should be fixed and the test suites enhanced to cover more cases.
    
  - Comparability for C/C++ and C# for windows

      The C/C++ version would essentially be a port of the existing
      binary DynComp from valgrind to DynamoRio or Pin.

      If an instrumentation interface similar to Java exists for C# then
      the C# version would probably be pretty similar to DynComp/Java

  - Mechanism to check invariants found by Daikon in programs (ie, add
    as assertions or some other mechanism).  Optimally it would be easy
    to read and edit.  Also it would be easy to update if new invariants
    are calculated

    (c.f. JML's RAC)

    From our project file:

      This project is, in brief, about writing a better assertion
      checker for Java.

      Most procedures have preconditions and postconditions.  Checking
      <em>preconditions</em> at run time is easy: just write an assert
      statement at the beginning of the routine.  Checking
      <em>postconditions</em> is more troublesome: one must give a
      name to the return value and insert an assertion at every exit
      point, including return statements and exceptional exits such as
      those caused by throwing an exception.  Furthermore, in this
      approach the postcondition is not documented at the beginning of
      the procedure.  <em>Object invariants</em> are similarly
      problematic: they must be duplicated for every procedure entry
      and exit in a class.

      Run-time checking of specifications seems deceptively easy, but
      has proved a difficult task.  We would like to perform the
      research and implementation that will enable creation of a
      robust specification (pre- and post-condition, and object
      invariant) checker &mdash; both for use in our own programming,
      and because it will enable interesting additional research.

  - Compare invariants calculated for different versions of an application
    and see if differences can be correlated with regression errors.

      - Dynamically detected invariants provide useful information but the
        quantity of such invariants can make it difficult to uncover the
        important items

      - Regression errors (errors introduced into previously working
        functionality by new features or other bug fixes) are a 
        significant problem.  Breaking an existing feature is very likely
        to have serious ramifications for users.

      - Analyzing only those invariants that have changed between
        two versions of a system may allow regression errors to be uncovered.
        The two versions could range from two separate releases to the
        differences between the current configuration management version and
        an engineers checkout.

  - Inference of types:  nullness, mutability, typestate

===========================================================================

Performance/scalability

  - Support for multiple processors 

      - With the exception of I/O, Daikon is naturally parallel
          - Each program point can be processed independently
          - Post processing (such as processing the hierarchy and splitting)
            can also be done in parallel
      - One thread could read the input file (or socket) and then hand
        off the input record to a worker thread.
      - Significant speedups should be possible (I/O time is (at least for
        significant input files) usually a small percentage of the total
        time).

  - Support for multiple computers (ie, splitting runs across a set of
    computers over a network -- cloud computing)

      - One process would read the input file (or socket) and then
        send records to separate processes.
      - A large number of processes (up to the number of program points
        that are instrumented) could be supported.
      - This would also largely eliminate memory constraints (since each
        program point is handled in a separate process).

  - Trace file binary format

  - Trace file shows only changed variables, not every variable

  - implement per-call-site sampling.  This may help scalability dramatically.

  - Optimize derived variables

      - Apply equality sets, constants, etc to the creation of derived
        variables.
      - Optionally limit derived variables to expressions seen in the
        program.

  - Ignore unused variables. Currently Daikon outputs data about all
    variables, but it would speed Daikon up to perform output only for
    variables that a given procedure may read or write. As a side benefit,
    this could also eliminate some irrelevant output.

===========================================================================

Algorithms

  - Infer some properties of multithreaded code, e.g., which variables are
    shared or which are protected by what locks, etc.

  - Statistically likely, but not entirely true, properties -- good for finding
    bugs or corner cases.  Related to splitting, or not?

  - Advance the basic techniques so that fewer settings are required to
    infer invariants and that less manual filtering is required.  Maybe
    even exploring more heuristics to automatically set the options?

  - Fix the usage of final statics and enums in Daikon.  It probably doesn't
    make sense to include these as separate variables since they are
    constants.  It might be both more efficient and provide better
    output to examine the one-ofs and other sample dependent invariants
    at the end of the run and substitute in constants where they
    match.

  - Reduce spurious (obvious and/or uninteresting) invariants in Daikon.   

      Daikon's output is can be too voluminous to be useful to programmers
      in understanding a program.  Some mechanism to reduce the number
      of invariants to a more manageable number could make Daikon 
      significantly more useful.  Some Java specific approaches are:

        - Remove obvious invariants over constants
        - Take advantage of Java type information (generic and otherwise)
        - Only include variables referenced in a routine (and the routines
          it calls)
        - Analyze output (with and without DynComp) on a number of real
          world programs.

  - Sequence/array invariant redesign

      Redesign invariants so that only scalar invariants need to be
      implemented directly.  All invariants over sequences
      (element-wise, pair-wise, and sequence invariants) would be
      automatically created from the scalar versions.  Element-wise,
      pair-wise, and sequence invariants would be extended to ternary
      invariants.

      Change the input dtrace record format so that arrays of classes
      or structs are represented directly in the input rather than 
      creating a separate array for each class/structure member.  This
      would simplify the front end and also allow invariants over nested
      arrays and more complex data structures.

      Fix array handling so that there can be nonsensical elements in arrays.

  - Extend non-instantiating suppressions

    There are a number of limitations to non-instantiating suppressions.
    The following is taken from the NIS presentation.  It has perhaps
    too much detail, but does provide specifics.

      - Suppressions are limited to one level
        - Invariants with suppressions cannot be antecedents
        - Could be resolved by recursively processing suppressions
        - Suppressions could be recursively expanded at definition time
            For example, (x &ge; y) could be replaced by (x = y) &or; (x > y)

      - Suppressions can only use stateless invariants
        - New stateless invariants augment existing sample dependent invariants
            - x = 1 rather than OneOf
            - x >= 0 rather than LowerBound
        - Requiring new invariants is not optimal
            - Memory is required to store the new invariants
            - Duplicate invariants are confusing

      Problems with using sample dependent invariants
        - Antecedent definition is more complex and requires state information
        - Determining when an antecedent is falsified is more complex
            - Falsification information is needed to determine if the
              last valid suppression was removed in a single pass
            - There is no state in a weakened invariant to indicate what
              has changed
            - Multiple antecedents can be falsified based on a single
              weakened invariant - (x = 3) invalidates (x = 0) and (x = 1)
        - Checking suppressions before and after each sample 
          rather than using a single pass could resolve this

      Suppressions can only use suppressee variables
        - All sets of variables that include the falsified
          antecedent must be considered
        - More difficult and expensive to determine the relationship 
          with derived variables
        - Consider (x[] = y[]) && (i = j) --> x[i] = y[j]
            - (x[] = y[]) is falsified
            - All variables derived from x[] and y[] must be considered
        - Case by case solutions should be straightforward
        - A general solution is less obvious

      - Suppression checking is expensive
          - All variable sets that include each falsified antecedent
            must be considered
          - The only shortcut occurs when the suppression is still valid
            (processing can stop on the first valid suppression)
          - Merging is particularly expensive, because all possible 
            suppressions over all sets of variables must be considered
          - Iterating over possible antecedents rather than possible
            variable sets may be a solution

      - Suppressions can't merge data from antecedents
          - The linear ternary optimization requires the internal state
            from linear binary and the constant
          - Antecedent invariants could be passed to an invariant 
            specific setup routine
          - If any of the involved variables are sometimes missing, this
            is not necessarily sound
          - The current implementation uses dynamic constants which
            are always present, and does not suffer from this problem

  - Temporal properties

===========================================================================

PPT hierarchy

  - Add subclasses and interfaces to the PPT hierarchy

      Currently the hierarchy only covers the relationship between
      method pre- and post-conditions and methods with the class the
      contains them.  Extending the hierarchy to include subclasses
      and interfaces would provide more interesting invariants (e.g.,
      interface invariants) and refine the results.  

  - Add exception exit points to the ppt hierarchy.  This would allow us
    to calculate invariants that were specific to exceptions (perhaps by
    type) and to non-exception execution.

      - Daikon currently supports a program point hierarchy.  Invariants
        are dynamically determined at the leaves of the hierarchy (eg,
        exit program points).  Higher points (such as classes) are 
        calulated by merging the invariants from each child (in invariant
        must be true at each child in order to be true at the parent).

      - This approach both optimizes run time (by only processing the data
        at the leaves) and improves output (by not replicating invariants
        true at a parent at each child).

      - Exception exits are not currently included (data from an exception
        exit is discarded)

      - Exceptional exits could be added, forming a tree similar to what
        is shown below.

                        all exits
                        ---------
                exception-exit  normal-exit

      About 5 years ago, we discussed this in a fair amount of detail.
      At the bottom of this file, you can find a proposal by Mike and a
      counter-proposal by Jeff

  - better support for splitting (more than two splits, additional automatic
    splits, etc)

      From our project file:

      A conditional invariant, also called an "implication", is true
      only some of the time rather than always; for instance, "if p !=
      null then *p > x".  ("*p > x" is not unconditionally true, but is
      only checked when "p != null" is true.)  Currently, the predicates
      must be selected before Daikon runs -- currently, there is a
      predefined set, a static analysis of the program text adds more,
      and users can specify additional ones manually.  Two key
      improvements should be made: new strategies for choosing
      predicates should be implemented, and the system should be made
      capable of selecting new predicates at runtime rather than
      selecting them <em>a priori</em>.  Another improvement would be
      finding ways to combine sets of predicates without suffering
      exponential blowup.

    The system is also currently limited to only two children.  Support for
    more than two children would allow more interesting implications to
    be found.

------------------------------------------------

Text from DSD paper:

Therefore, we extended Daikon so that all behaviors observed for a subclass
correctly influence the invariants of the superclass and vice versa. This
change was crucial in getting invariants of sufficient consistency for
ESC/Java to process automatically| otherwise we experienced contradictions
in our experiments that prevented further automatic reasoning. The change
is not directly related to the integration of Daikon and CnC, however. It
is an independent enhancement of Daikon, valid for any use of the inferred
invariants. We are in the process of implementing this enhancement directly
on Daikon. We describe in a separate paper [10] the exact algorithm for
computing the invariants so they are consistent with the observed behaviors
and as general as possible, while satisfying behavioral subtyping.
DSD-Crasher also modifies the CnC back-end: the heuristics used during
execution of the generated test cases to



Christoph Csallner notes two problems with Daikon's output:

  The current Daikon implementation does not produce invariants for
  interfaces. It also emits conflicting postconditions in case a method and
  the one it overrides are called with similar input values but produce
  different output values. Contradicting postconditions violate JML
  semantics and throw off tools like ESC/Java2.

A reasonable approach would be to enhance the program point hierarchy.  One
could produce interface invariants by creating a program point representing
each method in the interface, and making the program point a parent (in the
hierarchy) of each implementation of it.

For overriding methods, one could add a hierarchy relation between the two
versions of the method.  (This slightly changes the definition of the
hierarchy, but that change might well be desirable.)  Alternately (but
perhaps less desirably), one could apply the same technique as for
interfaces:  for each method, add a new program point, and add a Daikon
hierarchy relationship from it to any (overriding) definition.

His paper says:

  Executions of the overriding method do not affect at all the invariants
  of the overridden method and vice versa.

------------------------------------------------

Appendix A - Supporting Exception exits in the Daikon PPT Hierarchy

Mikes proposal:

  Add new program points for exceptional exit.

  Goals:
   * Create more complete specifications, such as "exsures" clauses.
   * Create more accurate preconditions, since presently all entries
     associated with exceptional exit are ignored.
   * Separate "expected" exceptions that don't necessarily indicate undesired
     behavior (while running a test suite) from "unexpected" exceptions that
     indicate a code failure.  (This is related to the above.)
   * Perhaps (for Lee and others), get output even when there is never an
     exit (a tail call to another routine, and eventually System.exit() is
     called without any return having occurred.


  Technique:

  The general idea is to add a new exit point for each declared Exception,
  plus one for undeclared Exceptions/Errors/Throwables.  

  There will be three types of procedure exit:
   * possibly many from return statements
   * possibly many resulting from throwing different declared exceptions
   * exactly one for throwing an undeclared exception (e.g., Error,
     RuntimeException, Throwable)

  What does the hierarchy look like?  For example, when combining exit points
  into a single aggregate exit point, how should the new exceptional program
  points factor in?  Undeclared exceptions should not be combined with normal
  returns, but how should declared exceptions be handled?  Should there be 2
  or 3 top-level exit points, and if 2, with what should declared exceptions
  be combined (probably the normal returns)?  These decisions affect what
  preconditions (and other invariants) are inferred for the routine.  I lean
  somewhat toward:

                      exit
                  /          \
         normalexit          declexception
        /    |    \           /         \
    exit1  exit2  exit3    declexc1  declexc2    error

  with the error point completely unrelated to any other point in the
  hierarchy.  But I haven't fully thought this through yet, so I welcome
  comments.


  Implementation:

  If a method declares that it throws DeclaredEx1, DeclaredEx2, and
  DeclaredEx3, then I transform it as follows.  The exceptions must be
  ordered from most to least general, lest latter ones have no chance of
  getting caught.  The Throwable clause isn't necessary if one of the
  declared exceptions is Throwable.

  This code:

    int foo() throws DeclaredEx1, DeclaredEx2, DeclaredEx3 {
      body
    }

  is transformed into one of the following:

    int foo() throws DeclaredEx1, DeclaredEx2, DeclaredEx3 {
      try {
        body            // includes instrumentation for normal entry and exit
      } catch (DeclaredEx1 daikon_exception_1) {
        print exceptional exit program point
        throw daikon_exception_1;               // rethrow
      } catch (DeclaredEx2 daikon_exception_2) {
        print exceptional exit program point
        throw daikon_exception_2;               // rethrow
      } catch (DeclaredEx3 daikon_exception_3) {
        print exceptional exit program point
        throw daikon_exception_3;               // rethrow
      } catch (java.lang.Throwable daikon_exception_4) {
        // for RuntimeException, Error, and any other undeclared Throwable
        print exceptional exit program point
        throw daikon_exception_4;               // rethrow
      }
    }

  or

    int foo() throws DeclaredEx1, DeclaredEx2, DeclaredEx3 {
      try {
        body            // includes instrumentation for normal entry and exit
      } catch (Throwable daikon_exception) {
        switch statement to print program point name
        print rest of exceptional exit program point
        throw daikon_exception;         // rethrow
      }
    }

Jeff's Proposal:

  It seems to me that the issue we are interested in with exceptions is
  whether or not the 'normal' invariants are violated as a result of an
  exception.  Are the invariants of an object not correctly set because
  of error exit?  Does an error exit indicate that an intended
  precondition was violated?

  It is not clear to me that we can make the assumption that declaring
  an exception implies that the invariants are maintained and the
  preconditions are ok and that not declaring it implies otherwise.

  Also, it seems that perhaps daikon can answer these questions and that
  would be an interesting result in and of itself.

  With the hierarchy as you have proposed, we exclude non-declared
  errors from the combined exit point (and thus from the enter point and
  object/class points).  We include declared errors at the combined exit
  point and its parents.

  It seems like it would be nice if we could easily see how the
  invariants differ at each level dependeng on whether or not error
  results were included.  That might nicely highlight unexpected
  results.  For example, if someone declares an exception, but not does
  not properly fix the invariants.  Consider an alternative hierarchy:

                Combined Object
                  /         \
        normal-Object        Declexc-obj
             |                    |
             |   Combined Enter   |
             |   /          \     |
        normalenter          declexc-enter
             |                    |
             |    combined exit   |
             |    /       \       |
         normalexit     declexception         
        /    |    \        /       \            
    exit1  exit2  exit3  declexc1  declexc2    error

  At each level we combine the error paths with the non-error paths.  If
  the invariants match (eg, normal-enter and declared-exception-enter
  have the same invariants), then everything would merge to the combined
  point (and probably nothing would need to be printed at the two
  contributing points).

  I think the two versions of the hierarchy would look very similar when
  the invariants were the same.  But when there were different
  invariants, (ie, error side is different from non-error side), these
  would be pointed out.  From the point of view of providing interesting
  information I think this would be good.  It also seems that this might
  be interesting for tools as well (eg, Carlos' error classifications).
  One could argue that any difference between the two trees is possibly
  indicative of a bug.

  This approach is more work.  We would need to create exception
  versions of each existing program point.  The creation of the
  hierarchy would have to be changed as well.  I don't think bottom up
  processing has to be changed significantly though.  I believe it
  should handle without any trouble having multiple parents for a child.
  There are also memory implications (because we need to create more
  program points).  But there are similar memory implications in the
  first hierarchy as well (there are a minimum of twice as many exit
  points).

  I'm not sure this is worth the extra effort, but it seems like it
  might be worth considering.

  Its also possible to extend this approach to non-declared exceptions
  as well. I tend to think this is not worth it.  Though it could indicate
  places were someone was assumming that that invariants were maintained and
  they were not.


