#if 0
Do not attempt to compile this file with a Java compiler such as javac.
You first need to preprocess it with cpp, the C preprocessor.
The correct way to build the system is to run 'make'.
#endif

#if !(defined(ARITY1) || defined(ARITY2) || defined(ARITY3))
  #error "One of ARITY1, ARITY2, or ARITY3 must be defined"
#endif

#if defined(ARITY1)
  #define PPTSLICE1 PptSlice1
  #define PPTSLICE1STRING "PptSlice1"
  #define NUM_TM 2
  #define ARITY 1
  #define VALUETRACKER1 ValueTracker.ValueTracker1
#elif defined(ARITY2)
  #define PPTSLICE1 PptSlice2
  #define PPTSLICE1STRING "PptSlice2"
  #define NUM_TM 4
  #define ARITY 2
  #define VALUETRACKER1 ValueTracker.ValueTracker2
#elif defined(ARITY3)
  #define PPTSLICE1 PptSlice3
  #define PPTSLICE1STRING "PptSlice3"
  #define NUM_TM 8
  #define ARITY 3
  #define VALUETRACKER1 ValueTracker.ValueTracker3
#else
  #error "One of ARITY1, ARITY2, or ARITY3 must be defined"
#endif

#if 0
Macro ORDER_VALUES forces values of interest to their original order.
This has a small execution cost -- see Vector values_order.
#endif
#define ORDER_VALUES

// ***** This file is automatically generated from PptSlice.java.jpp

package daikon;

import daikon.inv.*;

  import daikon.inv.unary.*;
  import daikon.inv.unary.scalar.*;
  import daikon.inv.unary.string.*;
  import daikon.inv.unary.sequence.*;
  import daikon.inv.unary.stringsequence.*;
  import daikon.inv.binary.*;
  import daikon.inv.binary.twoScalar.*;
  import daikon.inv.binary.twoSequence.*;
  import daikon.inv.binary.twoString.*;
  import daikon.inv.binary.sequenceScalar.*;
  import daikon.inv.ternary.*;
  import daikon.inv.ternary.threeScalar.*;

import java.util.logging.Logger;
import java.util.logging.Level;

import java.util.*;

import utilMDE.*;

// This file looks a *lot* like part of PptTopLevel.
// (That is fine; its purpose is similar and mostly subsumed by VarValues.)

public final class PPTSLICE1
  extends PptSlice
{
  // We are Serializable, so we specify a version to allow changes to
  // method signatures without breaking serialization.  If you add or
  // remove fields, you should change this number to the current date.
  static final long serialVersionUID = 20030822L;

  /**
   * Debug tracer
   **/
  public static final Logger debugSpecific = Logger.getLogger("daikon." + PPTSLICE1STRING);

  public static final Logger debugMerge = Logger.getLogger ("daikon.PptSlice.merge");

  // This is in PptSlice; do not repeat it here!
  // Invariants invs;


#if defined(ARITY1)
  public VarInfo var_info;
#endif

#if 0
  THESE ARE OLD COMMENTS, referring to a previous implementation.
#if defined(ARITY1)
  // values_cache maps (interned) values to 2-element arrays of
  // [num_unmodified, num_modified].
#elif defined(ARITY2)
  // values_cache maps (interned) values to 4-element arrays of
  // [num_unmod_unmod, num_unmod_mod, num_mod_unmod, num_mod_mod].
#elif defined(ARITY3)
  // values_cache maps (interned) values to 8-element arrays of
  // [uuu, uum, umu, umm, muu, mum, mmu, mmm].
  // That is, the first element is (unmod,unmod,unmod);
  // the second element is (unmod,unmod,mod); etc.
#endif
#endif

  VALUETRACKER1 values_cache;
  int[] tm_total = new int[NUM_TM];  // "tm" stands for "tuplemod"


  /**
   * Create a new PPTSLICE1.  Warning: do not rearrange the contents
   * of var_infos once this has been created, as flow order is already
   * set up after construction.
   **/
  public PPTSLICE1(PptTopLevel parent, VarInfo[] var_infos) {
    super(parent, var_infos);
    Assert.assertTrue(var_infos.length == ARITY);
#if defined(ARITY1)
    var_info = var_infos[0];
#endif
    Dataflow.init_pptslice_po(this);

    // 44 is used here because that's the most amount of values needed to be seen by some
    // of the Invariants before they become justified
    // values_cache = new ValueTracker(44);

    /* [INCR]
    // values_cache = new HashMap();
    // values_order  = new Vector();
    */ // [INCR]
    if (this.debugged || debug.isLoggable(Level.FINE) || debugSpecific.isLoggable(Level.FINE))
      debug.info("Created " + PPTSLICE1STRING + " " + this.name());
    if (Debug.logOn())
      Debug.log (getClass(), this, "Created");

    // Make the caller do this, because
    //  1. there are few callers
    //  2. do not want to instantiate all invariants all at once
    // instantiate_invariants();
  }

#if defined(ARITY1)
  PptSlice1(PptTopLevel parent, VarInfo var_info) {
    this(parent, new VarInfo[] { var_info });
  }
#elif defined(ARITY2)
  PptSlice2(PptTopLevel parent, VarInfo var_info1, VarInfo var_info2) {
    this(parent, new VarInfo[] { var_info1, var_info2 });
  }
#elif defined(ARITY3)
  PptSlice3(PptTopLevel parent, VarInfo var_info1, VarInfo var_info2, VarInfo var_info3) {
    this(parent, new VarInfo[] { var_info1, var_info2, var_info3 });
  }
#endif

  void instantiate_invariants() {
    Assert.assertTrue(!no_invariants);

    // This test should be done by caller (PptTopLevel):
    // if (isControlled()) return;

    // Instantiate invariants
    if (this.debugged || debug.isLoggable(Level.FINE) || debugSpecific.isLoggable(Level.FINE))
      debug.info("instantiate_invariants for " + name() + ": originally " + invs.size() + " invariants in " + invs);

    Vector new_invs = null;
#if defined(ARITY1)
    ProglangType rep_type = var_info.rep_type;
    boolean is_scalar = rep_type.isScalar();
    if (is_scalar) {
      new_invs = SingleScalarFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerScalar(44);
      }
    } else if (rep_type == ProglangType.INT_ARRAY) {
      new_invs = SingleScalarSequenceFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerScalarArray(44);
      }
    } else if (Daikon.dkconfig_enable_floats
               && rep_type == ProglangType.DOUBLE) {
      new_invs = SingleFloatFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerFloat(44);
      }
    } else if (Daikon.dkconfig_enable_floats
               && rep_type == ProglangType.DOUBLE_ARRAY) {
      new_invs = SingleFloatSequenceFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerFloatArray(44);
      }
    } else if (rep_type == ProglangType.STRING) {
      new_invs = SingleStringFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerString(44);
      }
    } else if (rep_type == ProglangType.STRING_ARRAY) {
      new_invs = SingleStringSequenceFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerStringArray(44);
      }
    } else {
      // Do nothing; do not even complain
    }
#elif defined(ARITY2)
    ProglangType rep1 = var_infos[0].rep_type;
    ProglangType rep2 = var_infos[1].rep_type;
    boolean rep1_is_scalar = rep1.isScalar();
    boolean rep2_is_scalar = rep2.isScalar();
    boolean rep1_is_float  = rep1.isFloat();
    boolean rep2_is_float  = rep2.isFloat();
    if (rep1_is_scalar && rep2_is_scalar) {
      new_invs = TwoScalarFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerTwoScalar(44);
      }
    } else if ((rep1 == ProglangType.STRING)
        && (rep2 == ProglangType.STRING)) {
      new_invs = TwoStringFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerTwoString(44);
      }
    } else if ((rep1 == ProglangType.INT)
               && (rep2 == ProglangType.INT_ARRAY)) {
      new_invs = SequenceScalarFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerScalarArrayScalar(44);
      }
    } else if ((rep1 == ProglangType.INT_ARRAY)
               && (rep2 == ProglangType.INT)) {
      new_invs = SequenceScalarFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerScalarArrayScalar(44);
      }
    } else if ((rep1 == ProglangType.INT_ARRAY)
               && (rep2 == ProglangType.INT_ARRAY)) {
      new_invs = TwoSequenceFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerTwoScalarArray(44);
      }
    } else if (rep1_is_float && rep2_is_float) {
      if (Daikon.dkconfig_enable_floats) {
        new_invs = TwoFloatFactory.instantiate(this);
        if (! Invariant.dkconfig_use_confidence) {
          values_cache = new ValueTracker.ValueTrackerTwoFloat(44);
        }
      }
    } else if ((rep1 == ProglangType.DOUBLE)
               && (rep2 == ProglangType.DOUBLE_ARRAY)) {
      if (Daikon.dkconfig_enable_floats) {
        new_invs = SequenceFloatFactory.instantiate(this);
        if (! Invariant.dkconfig_use_confidence) {
          values_cache = new ValueTracker.ValueTrackerFloatArrayFloat(44);
        }
      }
    } else if ((rep1 == ProglangType.DOUBLE_ARRAY)
               && (rep2 == ProglangType.DOUBLE)) {
      if (Daikon.dkconfig_enable_floats) {
        new_invs = SequenceFloatFactory.instantiate(this);
        if (! Invariant.dkconfig_use_confidence) {
          values_cache = new ValueTracker.ValueTrackerFloatArrayFloat(44);
        }
      }
    } else if ((rep1 == ProglangType.DOUBLE_ARRAY)
               && (rep2 == ProglangType.DOUBLE_ARRAY)) {
      if (Daikon.dkconfig_enable_floats) {
        new_invs = TwoSequenceFactoryFloat.instantiate(this);
        if (! Invariant.dkconfig_use_confidence) {
          values_cache = new ValueTracker.ValueTrackerTwoFloatArray(44);
        }
      }
    } else {
      // Do nothing; do not even complain
    }
#elif defined(ARITY3)
    ProglangType rep1 = var_infos[0].file_rep_type;
    ProglangType rep2 = var_infos[1].file_rep_type;
    ProglangType rep3 = var_infos[2].file_rep_type;
    if ((rep1 == ProglangType.INT)
        && (rep2 == ProglangType.INT)
        && (rep3 == ProglangType.INT)) {
      new_invs = ThreeScalarFactory.instantiate(this);
      if (! Invariant.dkconfig_use_confidence) {
        values_cache = new ValueTracker.ValueTrackerThreeScalar(44);
      }
    } else if ((rep1 == ProglangType.DOUBLE)
               && (rep2 == ProglangType.DOUBLE)
               && (rep3 == ProglangType.DOUBLE)) {
      if (Daikon.dkconfig_enable_floats) {
        new_invs = ThreeFloatFactory.instantiate(this);
        if (! Invariant.dkconfig_use_confidence) {
          values_cache = new ValueTracker.ValueTrackerThreeFloat(44);
        }
      }
    } else {
      // Do nothing; do not even complain
    }
#endif

    if (new_invs != null) {
      for (int i=0; i<new_invs.size(); i++) {
        Invariant inv = (Invariant) new_invs.get(i);
        if (inv == null)
          continue;
        addInvariant(inv);
      }
    }

    if (this.debugged || debug.isLoggable(Level.FINE) || debugSpecific.isLoggable(Level.FINE)) {
      debug.info("after instantiate_invariants " + PPTSLICE1STRING + " " + name() + " = " + this + " has " + invs.size() + " invariants in " + invs);
    }
    if ((this.debugged  || debugSpecific.isLoggable(Level.FINE)) && (invs.size() > 0)) {
      debug.info("the invariants are:");
      for (int i=0; i<invs.size(); i++) {
        Invariant inv = (Invariant) invs.get(i);
        debug.info("  " + inv.format());
        debug.info("    " + inv.repr());
      }
    }

  }

  /**
   * Set the number of samples for this slice to be at least count.
   **/
  public void set_samples (int count) {
    if (tm_total[0] < count) tm_total[0] = count;
    if (tm_total[1] < count) tm_total[1] = count;
#if defined(ARITY2) || defined(ARITY3)
    if (tm_total[2] < count) tm_total[2] = count;
    if (tm_total[3] < count) tm_total[3] = count;
#endif
#if defined(ARITY3)
    if (tm_total[4] < count) tm_total[4] = count;
    if (tm_total[5] < count) tm_total[5] = count;
    if (tm_total[6] < count) tm_total[6] = count;
    if (tm_total[7] < count) tm_total[7] = count;
#endif
  }

  // These accessors are for abstract methods declared in Ppt
  public int num_samples() {
#if defined(ARITY1)
    int result = tm_total[0] + tm_total[1];
#elif defined(ARITY2)
    int result = tm_total[0] + tm_total[1] + tm_total[2] + tm_total[3];
#elif defined(ARITY3)
    int result = tm_total[0] + tm_total[1] + tm_total[2] + tm_total[3]
      + tm_total[4] + tm_total[5] + tm_total[6] + tm_total[7];
#endif
    Assert.assertTrue(result >= 0);
    return result;
  }

  // Returns the number of distinct values stored in the ValueTracker
  // of this.
  public int num_values() {
    if (Invariant.dkconfig_use_confidence) {
      throw new Error("to be implemented");
    } else {
      if (values_cache != null) {
        return this.values_cache.num_values();
      } else {
        return 0;
      }
    }
  }

#if 0
  This method is only used by some twoSequence Invariants, like PairwiseIntComparison
#endif
#if defined(ARITY2)
  // Returns the number of distinct array element values stored in
  // this value tracker (only if the arrays are of equal length)
  public int num_elt_values() {
    if (Invariant.dkconfig_use_confidence) {
      throw new Error("to be implemented");
    } else {
      if (values_cache == null) {
        return 0;
      } else {
        return this.values_cache.num_elt_values();
      }
    }
  }
#endif

#if 0
  num_no_dup_values() is only used by NoDuplicates
  num_seq_index_values() is only used by SeqIndexComparison
#endif
#if defined(ARITY1)
  // Returns the number of arrays seen whose length was > 1
  public int num_no_dup_values() {
    if (Invariant.dkconfig_use_confidence) {
      throw new Error("to be implemented");
    } else {
      if (values_cache == null) {
        return 0;
      } else {
        return this.values_cache.num_no_dup_values();
      }
    }
  }

  // Returns the number of values seen as defined by
  // SeqIndexComparison.  That is, each distinct pair
  // (a[i], i) is considered a distinct value
  public int num_seq_index_values() {
    if (Invariant.dkconfig_use_confidence) {
      throw new Error("to be implemented");
    } else {
      if (values_cache == null) {
        return 0;
      } else {
        return this.values_cache.num_seq_index_values();
      }
    }
  }
#endif

  public int num_mod_non_missing_samples() {
#if defined(ARITY1)
    int result = tm_total[1];
#elif defined(ARITY2)
    int result = tm_total[1] + tm_total[2] + tm_total[3];
#elif defined(ARITY3)
    int result = tm_total[1] + tm_total[2] + tm_total[3]
       + tm_total[4] + tm_total[5] + tm_total[6] + tm_total[7];
#endif
    Assert.assertTrue(result >= 0);
    return result;
  }

#if defined(ARITY1)
  public String tuplemod_samples_summary() {
    Assert.assertTrue(! no_invariants);
    return "U=" + tm_total[0]
      + ", M=" + tm_total[1];
  }
#elif defined(ARITY2)
  public String tuplemod_samples_summary() {
    Assert.assertTrue(! no_invariants);
    return "UU=" + tm_total[0]
      + ", UM=" + tm_total[1]
      + ", MU=" + tm_total[2]
      + ", MM=" + tm_total[3];
  }
#elif defined(ARITY3)
  public String tuplemod_samples_summary() {
    Assert.assertTrue(! no_invariants);
    return "UUU=" + tm_total[0]
      + ", UUM=" + tm_total[1]
      + ", UMU=" + tm_total[2]
      + ", UMM=" + tm_total[3]
      + ", MUU=" + tm_total[4]
      + ", MUM=" + tm_total[5]
      + ", MMU=" + tm_total[6]
      + ", MMM=" + tm_total[7];
  }
#endif

  // public int num_missing() { return values_cache.num_missing; }

  // Accessing data
  int num_vars() {
    return var_infos.length;
  }
  Iterator var_info_iterator() {
    return Arrays.asList(var_infos).iterator();
  }


  boolean compatible(Ppt other) {
    // This insists that the var_infos lists are identical.  The Ppt
    // copy constructor does reuse the var_infos field.
    return (var_infos == other.var_infos);
  }

  ///////////////////////////////////////////////////////////////////////////
  /// Manipulating values
  ///


  /**
   * This procedure accepts a sample (a ValueTuple), extracts the values
   * from it, casts them to the proper types, and passes them along to the
   * invariants proper.  (The invariants accept typed values rather than a
   * ValueTuple that encapsulates objects of any type whatever.)
   **/
  public List add(ValueTuple full_vt, int count) {
    //     if (debugFlow.isLoggable(Level.FINE)) {
    //       debugFlow.fine ("<< Doing add for " + this.toString());
    //       StringBuffer sb = new StringBuffer();
    //       for (int i = 0; i < var_infos.length; i++) {
    //         VarInfo vi = var_infos[i];
    //         Object val = vi.getValue(full_vt);
    //         sb.append (" ");
    //         sb.append (ValueTuple.valToString (val));
    //       }
    //       debugFlow.fine ("    with values:" + sb);
    //     }

    Assert.assertTrue(! no_invariants);
    Assert.assertTrue(invs.size() > 0);
    // Assert.assertTrue(! already_seen_all); // [INCR]
    for (int i=0; i<invs.size(); i++) {
      Assert.assertTrue(invs.get(i) != null);
    }

    // if (Global.debugInfer.isLoggable(Level.FINE)) {
    //   Global.debugInfer.fine (PPTSLICE1STRING + ".add(" + full_vt + ", " + count + ")" + " for " + name());
    // }

    // Do not bother putting values into a slice if missing.

#if defined(ARITY1)
    VarInfo vi1 = var_info;
#elif defined(ARITY2)
    VarInfo vi1 = var_infos[0];
    VarInfo vi2 = var_infos[1];
#elif defined(ARITY3)
    VarInfo vi1 = var_infos[0];
    VarInfo vi2 = var_infos[1];
    VarInfo vi3 = var_infos[2];
#endif

    // If any var has encountered out of array bounds values,
    // stop all invariants in this slice.  The presumption here is that
    // an index out of bounds implies that the derived variable (eg a[i])
    // doesn't really make any sense (essentially that i is not a valid
    // index for a).  Invariants on the derived variable are thus not
    // relevant
    for (int i = 0; i < var_infos.length; i++) {
      if (var_infos[i].missingOutOfBounds()) {
        for (int j = 0; j < invs.size(); j++) {
          Invariant inv = (Invariant) invs.get(j);
          if (PrintInvariants.print_discarded_invariants)
            DiscReasonMap.put(inv, DiscardCode.bad_sample, var_infos[i].name.name() + " array index was out of bounds");
          destroyAndFlowInv(inv);
          if (inv.logOn())
            inv.log ("destroyed because " + var_infos[i].name.name()
                     + " array index out of bounds");
        }
        if (VarInfo.debugMissing.isLoggable (Level.FINE))
          VarInfo.debugMissing.fine ("Removing slice " + this +
                          " because var " + var_infos[i].name.name() +
                          " array index out of bounds");
        return flow_and_remove_falsified();
      }
    }

    int mod1 = full_vt.getModified(vi1);
    if (mod1 == ValueTuple.MISSING_FLOW || mod1 == ValueTuple.MISSING_NONSENSICAL) {
      // System.out.println("Bailing out of add(" + full_vt + ") for " + name());
      return emptyList;
    }
    if (mod1 == ValueTuple.STATIC_CONSTANT) {
      Assert.assertTrue(vi1.is_static_constant);
      mod1 = ((num_mod_non_missing_samples() == 0)
              ? ValueTuple.MODIFIED : ValueTuple.UNMODIFIED);
    }
#if defined(ARITY2) || defined(ARITY3)
    int mod2 = full_vt.getModified(vi2);
    if (mod2 == ValueTuple.MISSING_FLOW || mod2 == ValueTuple.MISSING_NONSENSICAL) {
      // System.out.println("Bailing out of add(" + full_vt + ") for " + name());
      return emptyList;
    }
    if (mod2 == ValueTuple.STATIC_CONSTANT) {
      Assert.assertTrue(vi2.is_static_constant);
      mod2 = ((num_mod_non_missing_samples() == 0)
              ? ValueTuple.MODIFIED : ValueTuple.UNMODIFIED);
    }
#endif
#if defined(ARITY3)
    int mod3 = full_vt.getModified(vi3);
    if (mod3 == ValueTuple.MISSING_FLOW || mod3 == ValueTuple.MISSING_NONSENSICAL) {
      // System.out.println("Bailing out of add(" + full_vt + ") for " + name());
      return emptyList;
    }
    if (mod3 == ValueTuple.STATIC_CONSTANT) {
      Assert.assertTrue(vi3.is_static_constant);
      mod3 = ((num_mod_non_missing_samples() == 0)
              ? ValueTuple.MODIFIED : ValueTuple.UNMODIFIED);
    }
#endif
    Object val1 = full_vt.getValue(vi1);
    Assert.assertTrue (Intern.isInterned (val1));
#if defined(ARITY2) || defined(ARITY3)
    Object val2 = full_vt.getValue(vi2);
    Assert.assertTrue (Intern.isInterned (val2));
#endif
#if defined(ARITY3)
    Object val3 = full_vt.getValue(vi3);
    Assert.assertTrue (Intern.isInterned (val3));
#endif

    // if (! already_seen_all) // [INCR]
    {
      /* [INCR] ...
#if defined(ARITY1)
      Object vals = val1;
#elif defined(ARITY2)
      Object[] vals = Intern.intern(new Object[] { val1, val2 });
#elif defined(ARITY3)
      Object[] vals = Intern.intern(new Object[] { val1, val2, val3 });
#endif
      int[] tm_arr = (int[]) values_cache.get(vals);
      if (tm_arr == null) {
        tm_arr = new int[NUM_TM];
        values_cache.put(vals, tm_arr);
        values_order.add (vals);
      }
      */ // ... [INCR]
    }
    // System.out.println(PPTSLICE1STRING + " " + name() + ": add " + full_vt + " = " + vt);
    // System.out.println(PPTSLICE1STRING + " " + name() + " has " + invs.size() + " invariants.");
    // defer_invariant_removal(); [INCR]
    // Supply the new values to all the invariant objects.
    int num_invs = invs.size();
    Assert.assertTrue((mod1 == vi1.getModified(full_vt))
                  || ((vi1.getModified(full_vt) == ValueTuple.STATIC_CONSTANT)
                      && ((mod1 == ValueTuple.UNMODIFIED)
                          || (mod1 == ValueTuple.MODIFIED))));

#if defined(ARITY1)
    add_val (val1, mod1, count);
#elif defined(ARITY2)
    add_val (val1, val2, mod1, mod2, count);
#elif defined(ARITY3)
    add_val (val1, val2, val3, mod1, mod2, mod3, count);
#endif

    // undefer_invariant_removal(); [INCR]
    return flow_and_remove_falsified();
  }

#if defined (ARITY1)
  public void add_val (Object val1, int mod1, int count) {

    tm_total[mod1] += count;

    Assert.assertTrue(mod1 != ValueTuple.MISSING_FLOW
                      && mod1 != ValueTuple.MISSING_NONSENSICAL);
    if (! Invariant.dkconfig_use_confidence) {
      if (values_cache != null) {
        values_cache.add(val1);
      }
    }
    for (int i=0; i < invs.size(); i++) {
      UnaryInvariant inv = (UnaryInvariant) invs.get(i);
      if (inv.falsified) continue;
      if (inv.getSuppressor() != null) continue;
      Invariant clone = (Invariant) inv.clone();
      InvariantStatus status = inv.add(val1, mod1, count);
      if (status == InvariantStatus.FALSIFIED) {
        destroyAndFlowInv(inv);
      } else if (status == InvariantStatus.WEAKENED) {
        flowClone(inv, clone);
      }
      if (PrintInvariants.print_discarded_invariants && inv.falsified) {
        DiscReasonMap.put(inv, DiscardCode.bad_sample,
          "Falsified from sample: " + var_infos[0].name.name() + " = "
          + (var_infos[0].rep_type.isArray() ? ArraysMDE.toString(val1) : val1));
      }
    }
  }
#elif defined (ARITY2)

  public void add_val (Object val1, Object val2, int mod1, int mod2, int count) {

    Assert.assertTrue ((mod1 != ValueTuple.MISSING_FLOW
                       && mod1 != ValueTuple.MISSING_NONSENSICAL)
                       && (mod2 != ValueTuple.MISSING_FLOW
                       && mod2 != ValueTuple.MISSING_NONSENSICAL));

    int mod_index = mod1 * 2 + mod2;
    tm_total[mod_index] += count;
    if (Debug.logDetail())
      Debug.log (getClass(), this, "mod1 = " + mod1 + " mod2 = " + mod2
                 + " count = " + count);

    boolean array1 = var_infos[0].rep_type.isArray();
    boolean array2 = var_infos[1].rep_type.isArray();
    if (! Invariant.dkconfig_use_confidence) {
      if (values_cache != null) {
        if (array2 && ! array1) {
          values_cache.add(val2, val1);
        } else {
          values_cache.add(val1, val2);
        }
      }
    }
    if (array2 && ! array1) {
      for (int i=0; i < invs.size(); i++) {
        BinaryInvariant inv = (BinaryInvariant) invs.get(i);
        if (inv.falsified) continue;
        if (inv.getSuppressor() != null) continue;
        Invariant clone = (Invariant) inv.clone();
        InvariantStatus status = inv.add(val2, val1, mod1, count);
        if (status == InvariantStatus.FALSIFIED) {
          destroyAndFlowInv(inv);
        } else if (status == InvariantStatus.WEAKENED) {
          flowClone(inv, clone);
        }
        if (PrintInvariants.print_discarded_invariants && inv.falsified) {
          DiscReasonMap.put(inv, DiscardCode.bad_sample,
                            "Falsified from sample: " +
                            var_infos[0].name.name() +
                            " = " + val1 + "," + var_infos[1].name.name() +
                            " = " + ArraysMDE.toString(val2));
        }
      }
    } else {
      for (int i=0; i < invs.size(); i++) {
        BinaryInvariant inv = (BinaryInvariant) invs.get(i);
        if (inv.falsified) continue;
        if (inv.getSuppressor() != null) continue;
        Invariant clone = (Invariant) inv.clone();
        InvariantStatus status = inv.add(val1, val2, mod1, count);
        if (status == InvariantStatus.FALSIFIED) {
          destroyAndFlowInv(inv);
        } else if (status == InvariantStatus.WEAKENED) {
          flowClone(inv, clone);
        }
        if (PrintInvariants.print_discarded_invariants && inv.falsified) {
          if (array1 && array2 && (!( (inv instanceof SeqSeqIntEqual)
              || (inv instanceof SeqSeqFloatEqual)
              || (inv instanceof SeqSeqStringEqual) ))
              && ArraysMDE.length(val1) != ArraysMDE.length(val2)) {
            // No need to print out two potentially huge arrays if the
            // reason for discard was because of different array lengths
            DiscReasonMap.put(inv, DiscardCode.bad_sample,
                                "Samples seen with different array lengths");
          } else {
            DiscReasonMap.put(inv, DiscardCode.bad_sample,
                    "Falsified from sample: " + var_infos[0].name.name()
                    + " = " + (array1 ? ArraysMDE.toString(val1) : val1)
                    + "," + var_infos[1].name.name()
                    + " = " + (array2 ? ArraysMDE.toString(val2) : val2));
          }
        }
      }
    }
  }
#elif defined (ARITY3)
  public void add_val (Object val1, Object val2, Object val3,
                       int mod1, int mod2, int mod3, int count) {

    Assert.assertTrue ((mod1 != ValueTuple.MISSING_FLOW
                        && mod1 != ValueTuple.MISSING_NONSENSICAL)
                        && (mod2 != ValueTuple.MISSING_FLOW
                        && mod2 != ValueTuple.MISSING_NONSENSICAL)
                        && (mod3 != ValueTuple.MISSING_FLOW
                        && mod3 != ValueTuple.MISSING_NONSENSICAL));

    int mod_index = mod1 * 4 + mod2 * 2 + mod3;
    tm_total[mod_index] += count;

    if (! Invariant.dkconfig_use_confidence) {
      if (values_cache != null) {
        values_cache.add(val1, val2, val3);
      }
    }

    // Debug print add info
    if (Debug.logDetail())
      Debug.log (getClass(), this, "Adding values: " + val1 + ", " + val2
                 + ", " + val3);

    for (int i=0; i < invs.size(); i++) {
      TernaryInvariant inv = (TernaryInvariant) invs.get(i);
      if (inv.falsified) continue;
      if (inv.getSuppressor() != null) continue;
      Invariant clone = (Invariant) inv.clone();
      InvariantStatus status = inv.add(val1, val2, val3, mod1, count);
      if (status == InvariantStatus.FALSIFIED) {
        destroyAndFlowInv(inv);
      } else if (status == InvariantStatus.WEAKENED) {
        flowClone(inv, clone);
      }
      if (PrintInvariants.print_discarded_invariants && inv.falsified) {
        // Currently there are no ternary invariants with arrays, but if
        // there are in the future, I don't want this to break.
        DiscReasonMap.put(inv, DiscardCode.bad_sample,
          "Falsified from sample: " + var_infos[0].name.name() + " = "
          + (var_infos[0].rep_type.isArray() ? ArraysMDE.toString(val1) : val1)
          + "," + var_infos[1].name.name() + " = "
          + (var_infos[1].rep_type.isArray() ? ArraysMDE.toString(val2) : val2)
          + "," + var_infos[2].name.name() + " = "
          + (var_infos[2].rep_type.isArray() ? ArraysMDE.toString(val3) : val3));
      }
    }
  }
#endif

//   private void destroyInv(Invariant inv) {
//     inv.falsified = true;
//     if (PrintInvariants.print_discarded_invariants)
//       parent.falsified_invars.add(this);
//     removeInvariant(inv);
//   }

  public void addInvariant(Invariant invariant) {
    Assert.assertTrue(invariant != null);

    invs.add(invariant);
    Global.instantiated_invariants++;
    if (Global.debugStatistics.isLoggable(Level.FINE) || this.debugged || debugSpecific.isLoggable(Level.FINE))
      debug.info("instantiated_invariant: " + invariant.format()
                 // [INCR] + "; " + "already_seen_all=" + already_seen_all
                 );
    if (invariant.logOn())
      invariant.log ("Instantiated " + invariant.format());

    /* [INCR] ... I think this is now unnecessary; not sure. XXX
    if (already_seen_all) {
      // Make this invariant up to date by supplying it with all the values
      // which have already been seen.
      // (Do not do
      //   Assert.assertTrue(values_cache.entrySet().size() > 0);
      // because all the values might have been missing.  We used to ignore
      // variables that could have some missing values, but no longer.)
#if defined(ARITY1)
      UnaryInvariant inv = (UnaryInvariant) invariant;
      for (Iterator itor = values_cache.entrySet().iterator() ; itor.hasNext() ; ) {
        Map.Entry entry = (Map.Entry) itor.next();
        Object val = entry.getKey();
        int[] tm_array = (int[]) entry.getValue();
        InvariantStatus status1 = inv.add(val, 0, tm_array[0]);
        InvariantStatus status2 = inv.add(val, 1, tm_array[1]);
        if (status1 == InvariantStatus.FALSIFIED ||
            status2 == InvariantStatus.FALSIFIED) {
          destroyInv(inv);
          break;
        }
      }
#elif defined(ARITY2)
      VarInfo vi1 = var_infos[0];
      VarInfo vi2 = var_infos[1];
      boolean array1 = vi1.rep_type.isArray();
      boolean array2 = vi2.rep_type.isArray();
      boolean doublearray1 = vi1.rep_type == ProglangType.DOUBLE_ARRAY;
      boolean doublearray2 = vi2.rep_type == ProglangType.DOUBLE_ARRAY;
        // Make this invariant up to date by supplying it with all the values.
        for (Iterator itor = values_cache.entrySet().iterator() ; itor.hasNext() ; ) {
          Map.Entry entry = (Map.Entry) itor.next();
          Object[] vals = (Object[]) entry.getKey();
          int[] tm_array = (int[]) entry.getValue();
          InvariantStatus status = InvariantStatus.NO_CHANGE;
          for (int mi=0; mi<tm_array.length; mi++) {
            if (tm_array[mi] > 0) {
              InvariantStatus tempStatus =
                inv.add(seqval, sclval, mi, tm_array[mi]);
              if (tempStatus == InvariantStatus.FALSIFIED) {
                status = InvariantStatus.FALSIFIED;
                break;
              }
            }
          }
          if (status == InvariantStatus.FALSIFIED) {
            destroyInv(inv);
            break;
          }
        }
#if defined (ORDER_VALUES)
        // Make this invariant up to date by supplying it with all the values.
        Assert.assertTrue (values_order.size() == values_cache.size());
        for (Iterator itor = values_order.iterator() ; itor.hasNext() ; ) {
          Object[] vals = (Object[]) itor.next();
          int[] tm_array = (int[]) values_cache.get (vals);
          InvariantStatus status = InvariantStatus.NO_CHANGE;
          for (int mi=0; mi<tm_array.length; mi++) {
            if (tm_array[mi] > 0) {
              InvariantStatus tempStatus =
                inv.add(val1, val2, mi, tm_array[mi]);
              if (tempStatus == InvariantStatus.FALSIFIED) {
                status = InvariantStatus.FALSIFIED;
                break;
              }
            }
          }
          if (status == InvariantStatus.FALSIFIED) {
            destroyInv(inv);
            break;
          }
        }
#endif
        // Make this invariant up to date by supplying it with all the values.
        for (Iterator itor = values_cache.entrySet().iterator() ; itor.hasNext() ; ) {
          Map.Entry entry = (Map.Entry) itor.next();
          Object[] vals = (Object[]) entry.getKey();
          int[] tm_array = (int[]) entry.getValue();
          InvariantStatus status = InvariantStatus.NO_CHANGE;
          for (int mi=0; mi<tm_array.length; mi++) {
            if (tm_array[mi] > 0) {
              InvariantStatus tempStatus =
                inv.add(val1, val2, mi, tm_array[mi]);
              if (tempStatus == InvariantStatus.FALSIFIED) {
                status = InvariantStatus.FALSIFIED;
                break;
              }
            }
          }
          if (status == InvariantStatus.FALSIFIED) {
            destroyInv(inv);
            break;
          }
        }
      }
#elif defined(ARITY3)
      VarInfo vi1 = var_infos[0];
      VarInfo vi2 = var_infos[1];
      VarInfo vi3 = var_infos[2];
      ProglangType rep1 = vi1.rep_type;
      ProglangType rep2 = vi2.rep_type;
      ProglangType rep3 = vi3.rep_type;
#if defined (ORDER_VALUES)
        for (Iterator itor = values_order.iterator(); itor.hasNext(); ) {
          Object[] vals = (Object[]) itor.next();
          int[] tm_array = (int[]) values_cache.get (vals);
          InvariantStatus status = InvariantStatus.NO_CHANGE;
          for (int mi=0; mi<tm_array.length; mi++) {
            if (tm_array[mi] > 0) {
              InvariantStatus tempStatus =
                inv.add(val1, val2, val3, mi, tm_array[mi]);
              if (tempStatus == InvariantStatus.FALSIFIED) {
                status = InvariantStatus.FALSIFIED;
                break;
              }
            }
          }
          if (status == InvariantStatus.FALSIFIED) {
            destroyInv(inv);
            break;
          }
        }
#endif
        for (Iterator itor = values_cache.entrySet().iterator(); itor.hasNext(); ) {
          Map.Entry entry = (Map.Entry) itor.next();
          Object[] vals = (Object[]) entry.getKey();
          int[] tm_array = (int[]) entry.getValue();
          InvariantStatus status = InvariantStatus.NO_CHANGE;
          for (int mi=0; mi<tm_array.length; mi++) {
            if (tm_array[mi] > 0) {
              InvariantStatus tempStatus =
                inv.add(val1, val2, val3, mi, tm_array[mi]);
              if (tempStatus == InvariantStatus.FALSIFIED) {
                status = InvariantStatus.FALSIFIED;
                break;
              }
            }
          }
          if (status == InvariantStatus.FALSIFIED) {
            destroyInv(inv);
            break;
          }
        }
      }
#endif
    }
    */ // ... [INCR]
  }

  /**
   * @see daikon.PptSlice#cloneOnePivot(VarInfo leader, VarInfo newLeader)
   **/
  protected PptSlice cloneAndPivot (VarInfo[] argNewVarInfos) {
    VarInfo[] newVarInfos = new VarInfo[arity];
    // rename the VarInfo references to subsitute newLeader for leader
    int [] permutation = new int[arity];
    for (int i = 0; i < arity; i++) {
      newVarInfos[i] = argNewVarInfos[i];
      permutation[i] = i;
    }

    // Now sort both of the above arrays, by using index comparisons
    // on the former.  Why am I hard-wiring?  Because Java doesn't
    // have a double-array sort routine, and slice sizes won't exceed
    // 3.
    for (int i = 0; i < arity - 1; i++) {
      for (int j = arity - 2; j >= i; j--) {
        VarInfo tempVi;
        int temp;
        if (newVarInfos[j].varinfo_index > newVarInfos[j+1].varinfo_index) {
          tempVi = newVarInfos[j];
          newVarInfos[j] = newVarInfos[j+1];
          newVarInfos[j+1] = tempVi;

          temp = permutation[j];
          permutation[j] = permutation[j+1];
          permutation[j+1] = temp;
        }
      }
    }

    // Assert sorted
    for (int i = 0; i < arity - 1; i++) {
      Assert.assertTrue (newVarInfos[i].varinfo_index <= newVarInfos[i+1].varinfo_index);
    }
    permutation = ArraysMDE.fn_inverse_permutation(permutation);

    Assert.assertTrue(ArraysMDE.fn_is_permutation(permutation));
    // Assert that the permutation represents the rearrangement
    for (int i=0; i < arity; i++) {
      // the variable that used to be at position "i" is now found at
      // position permutation[i].
      VarInfo oldvi = argNewVarInfos[i];
      VarInfo newvi = newVarInfos[permutation[i]];
      Assert.assertTrue(oldvi == newvi);
    }

    // Why not just clone?  Because then index order wouldn't be
    // preserved
    PPTSLICE1 result = new PPTSLICE1 (this.parent, newVarInfos);

    // Set sample counts
    for (int i = 0; i < tm_total.length; i++) {
      result.tm_total[i] = this.tm_total[i];
    }

    // Set ValueTracker
    if (! Invariant.dkconfig_use_confidence) {
      if (values_cache == null) {
        result.values_cache = null;
      } else {
        result.values_cache = (VALUETRACKER1) this.values_cache.clone();
        result.values_cache.permute (permutation);
      }
    }

    // re-parent the invariants and copy them out
    List newInvs = new LinkedList();
    for (Iterator i = invs.iterator(); i.hasNext(); ) {
      Invariant inv = (Invariant) i.next();
      Assert.assertTrue (inv.ppt == this);
      Invariant newInv = inv.transfer (result, permutation);
      // if (!newInv.isObvious()) {
      newInvs.add (newInv);
      parent.attemptSuppression (newInv, true);
      Assert.assertTrue (newInv != inv);
      Assert.assertTrue (newInv.ppt == result);
      Assert.assertTrue (inv.ppt == this);
      // }
    }

    result.invs.addAll (newInvs);
    if (PptSliceEquality.debug.isLoggable(Level.FINE)) {
      PptSliceEquality.debug.fine ("cloneAndPivot: newInvs " + invs);
    }
    result.repCheck();
    return result;
  }
  /**
   * Creates invariants at this ppt by merging invariants from each of its
   * children.  An invariant must exist at each of the children in order
   * for it to be created here (at the parent).  Additionally, some invariants
   * have state information that must be merged.  This is done by the invariant
   * itself.
   *
   * The basic steps are:
   *
   *    1)  Find all of the child invariants.  These are the invariants in
   *        the matching slice of each child.
   *
   *    2)  For each invariant class, build a list of all of the invariants
   *        of that class.  Note that some invariant classes
   *        (eg, functionBinary) contain distinct invariants, each of which
   *        must be merged separately.  See Invariant.Match for more
   *        information concerning what makes an invariant the 'same'
   *
   *    3)  Each invariant that is found at each of the children is then
   *        merged to possibly create a parent invariant.
   */

  public void merge_invariants() {

    if (debugMerge.isLoggable (Level.FINE)) {
      debugMerge.fine ("merging invs for " + name());
    }

    // List of all invariants found over all of the children
    List all_invs = new ArrayList();

    // Keep count of the number of valid children processed.  An invariant
    // must be found at each valid child in order to exit at the parent.
    // A valid child is one that has received samples and has a corresponding
    // variable for each parent variable
    int valid_child_count = 0;

    // List of value caches from each child slice.
    List vtlist = new ArrayList();

    // Loop through all of the children of our top level parent
    child_loop:
    for (int i = 0; i < parent.children.size(); i++) {
      PptRelation rel = (PptRelation) parent.children.get(i);
      PptTopLevel ppt = rel.child;

      // Skip any children that have not seen any samples
      if (ppt.num_samples() == 0) {
        if (debugMerge.isLoggable (Level.FINE))
          debugMerge.fine ("-- slice ignored (no samples) " + ppt.name());
        continue;
      }

      // Child variable info
      VarInfo cvis[] = new VarInfo[var_infos.length];
      VarInfo cvis_sorted[] = new VarInfo[var_infos.length];
      int permute[] = new int[var_infos.length];

      // Build the corresponding array of VarInfos for the child.  If any
      // of the vars don't exist in this child, skip the child (since we
      // won't have data for each variable).
      for (int j = 0; j < var_infos.length; j++) {
        VarInfo pv = var_infos[j];
        VarInfo cv = rel.childVar (pv);
        if (cv == null)
          continue child_loop;
        cvis[j] = cv.canonicalRep();
        cvis_sorted[j] = cv.canonicalRep();
      }

      // If any of the child variables have always been missing, this
      // particular slice in the child received no samples.  If dynamic
      // constants are enabled, the slice will have never been created.
      // These slices can be skipped unless they contain a missing out of
      // bound var.  Out of bounds variables destroy all invariants in
      // the slice (since the variable is deemed to be nonsensical)
      if (slice_missing (ppt, cvis)) {
        if (debugMerge.isLoggable (Level.FINE))
          debugMerge.fine ("-- slice ignored (missing) " + ppt.name()
                           + " vars " + Debug.toString (cvis_sorted));
        continue;
      }

      // The child variables must be sorted by their index (in the child)
      Arrays.sort (cvis_sorted, VarInfo.IndexComparator.getInstance());

      // Keep track of the number of valid children
      valid_child_count++;

      // Find the corresponding slice.  If the slice does not exist or
      // has no invariants, there can be no invariants to merge (since
      // invariants must exist at each child to exist at the parent)
      PPTSLICE1 cslice = (PPTSLICE1) ppt.findSlice (cvis_sorted);
      if ((cslice == null) || (cslice.invs.size() == 0)) {
        if (debugMerge.isLoggable (Level.FINE))
          debugMerge.fine ("-- slice not found " + ppt.name()
                           + " vars " + Debug.toString (cvis_sorted));
        return;
      }

      // Update sample count info
      for (int j = 0; j < tm_total.length; j++) {
        tm_total[j] += cslice.tm_total[j];
      }

      // Keep track of the values cache from each child
      if (! Invariant.dkconfig_use_confidence) {
        vtlist.add (cslice.values_cache);
        if (Debug.logOn())
          Debug.log (getClass(), this, "Adding value cache "
                     + cslice.values_cache + "from ppt" + cslice.name());
      }

      // Build the permutation array from child to parent slice
      for (int j = 0; j < cvis_sorted.length; j++) {
        for (int k = 0; k < cvis.length; k++) {
          if (cvis_sorted[j] == cvis[k]) {
            permute[j] = k;
            cvis[k] = null;  // don't match the same one twice
            break;
          }
        }
      }

      // Debug print child vars and permute to parent
      if (debugMerge.isLoggable (Level.FINE)) {
        debugMerge.fine ("-- Processing child " + ppt.name() + " ("
                         + rel.getRelationType() + ")");
        debugMerge.fine ("-- -- child vars = "
                         + VarInfo.toString (cvis_sorted));
        debugMerge.fine ("-- -- parent vars = "
                         + VarInfo.toString (var_infos));
        debugMerge.fine ("-- -- permute = " + ArraysMDE.toString (permute));
      }

      // Add each invariant (permutted to match the parent varinfos)
      // to our list of invariants
      for (int j = 0; j < cslice.invs.size(); j++) {
        Invariant orig_inv = (Invariant) cslice.invs.get (j);
        Invariant inv = orig_inv.clone_and_permute (permute);
        all_invs.add (inv);
        if (inv.logOn()) {
          VarInfo[] child_vars = new VarInfo[var_infos.length];
          for (int k = 0; k < var_infos.length; k++) {
            VarInfo pv = var_infos[k];
            VarInfo cv = rel.childVar (pv);
            child_vars[k] = cv.canonicalRep();
          }
          orig_inv.log ("org inv");
          inv.log ("Created " + inv + " from " + orig_inv + " using permute "
                   + ArraysMDE.toString(permute) + " cvis_sorted = "
                   + VarInfo.toString (cvis_sorted) + " cvis = "
                   + VarInfo.toString (child_vars));
        }
      }
    }

    if (debugMerge.isLoggable (Level.FINE) && (valid_child_count == 0))
      debugMerge.fine ("-- No valid children found");

    // For each invariant found, find the list of invariants of the
    // same type (type corresponds basically but not exactly to the
    // invariants class) and add the invariant to that list.
    // Invariant.Match.equals() defines if two invariants are of the
    // same 'type' for the purpose of merging invariants.
    Map inv_map = new LinkedHashMap();
    for (int i = 0; i < all_invs.size(); i++) {
      Invariant inv = (Invariant) all_invs.get (i);
      Invariant.Match imatch = new Invariant.Match (inv);
      ArrayList invs = (ArrayList) inv_map.get (imatch);
      if (inv.logOn()) {
        inv.log ("Adding " + inv.format() + " to " + name()
                 + " invs list " + invs);
      }
      if (invs == null) {
        invs = new ArrayList();
        inv_map.put (imatch, invs);
      }
      invs.add (inv);
    }

    // Create value tracker information for the parent.
    if (! Invariant.dkconfig_use_confidence) {
      if (vtlist.size() > 0)
        values_cache = (VALUETRACKER1) ValueTracker.merge (vtlist);
    } else {
      Assert.assertTrue(vtlist.size() == 0);
    }

    // Attempt to create a parent invariant for each invariant that
    // appeared at each valid child.  Note that some invariants will
    // not exist at the parent even if they exist at each child (eg,
    // LinearBinary)
    for (Iterator j = inv_map.values().iterator(); j.hasNext(); ) {
      ArrayList child_invs = (ArrayList) j.next();
      if (child_invs.size() > valid_child_count) {
        // this shouldn't happen
        System.out.println ("Found " + child_invs.size() + " invariants at "
                         + name() + " (" + valid_child_count + " children)");
        for (int k = 0; k < child_invs.size(); k++ )
          System.out.println ("-- Invariant = "
                            + ((Invariant) child_invs.get(k)).format());
        Assert.assertTrue (child_invs.size() <= valid_child_count);
      }
      if (child_invs.size() == valid_child_count) {
        Invariant first = (Invariant) child_invs.get(0);
        if (Debug.logOn())
          first.log ("Attempting merge of " + child_invs.size()
                     + " invariants into ppt " + name());
        Invariant parent_inv = first.merge (child_invs, this);
        if (parent_inv != null) {
          invs.add (parent_inv);
          if (dkconfig_remove_merged_invs)
            remove_matching_invs (parent_inv, child_invs);
          if (Debug.logOn())
            parent_inv.log ("Merge successful");
        }
      } else {
        if (Debug.logOn()) {
          Invariant inv = (Invariant) child_invs.get(0);
          inv.log ("Not merging invariant up, Found " + child_invs.size()
                    + "child invariants in " + valid_child_count + " children");
        }
      }
    }
  }

  /**
   * Returns whether or not the slice is missing due to having one or more
   * of its variables always missing.  This returns true only for missing
   * flow and/or missing nonsensical.  Out of Bounds is treated differently
   * since it destroys all of its invariants
   */
  private boolean slice_missing (PptTopLevel ppt, VarInfo[] vis) {

    if (ppt.constants != null) {
      #if defined(ARITY1)
        if (ppt.constants.is_missing(vis[0])
            && !vis[0].missingOutOfBounds())
          return(true);
      #elif defined(ARITY2)
        if ((ppt.constants.is_missing(vis[0])
             || ppt.constants.is_missing(vis[1]))
            && !vis[0].missingOutOfBounds()
            && !vis[1].missingOutOfBounds())
          return(true);
      #elif defined(ARITY3)
        if ((ppt.constants.is_missing(vis[0])
             || ppt.constants.is_missing(vis[1])
             || ppt.constants.is_missing(vis[2]))
            && !vis[0].missingOutOfBounds()
            && !vis[1].missingOutOfBounds()
            && !vis[2].missingOutOfBounds())
          return(true);
      #endif
    }
    return (false);
  }

  private void remove_matching_invs (Invariant parent_inv,
                                     List /*Invariant*/ child_invs) {

    for (int i = 0; i < child_invs.size(); i++) {
      Invariant child_inv = (Invariant) child_invs.get (i);
      if (parent_inv.isSameFormula (child_inv)
          && (child_inv.numSuppressees() == 0))
//         if (child_inv.ppt.var_infos[0].name.name().equals ("capacity"))
//           System.out.println ("removing inv " + child_inv + "in ppt "
//                               + child_inv.ppt + " parent inv = " + parent_inv
//                               + " in ppt " + parent_inv.ppt);
//         if (!child_inv.ppt.invs.contains(child_inv))
//           System.out.println ("inv " + child_inv + " not in its ppt "
//                               + child_inv.ppt + " parent inv = " + parent_inv
//                               + " in ppt " + parent_inv.ppt);

        if (child_inv.ppt.invs.contains(child_inv))
          child_inv.ppt.removeInvariant (child_inv);
    }
  }
}
